{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qjl6x6og3uXH"
   },
   "source": [
    "# HW 2 - Разложение матриц градиентным методом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sv79QFb_-oNZ"
   },
   "source": [
    "Цель задания: В ходе реализации [разложения Таккера](https://proceedings.neurips.cc/paper/2018/file/45a766fa266ea2ebeb6680fa139d2a3d-Paper.pdf) градиентным методом освоить pyTorch и реализовать подходы оптимизации параметров модели (в отсутствии готовых решений)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HUSrylpBwYn"
   },
   "source": [
    "[Более-менее внятное описание алгоритма канонического разложения](https://www.alexejgossmann.com/tensor_decomposition_tucker/) - само аналитическое разложение вам реализовывать НЕ НУЖНО"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "P1PuoBtG7iw7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c9803c3f50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.linalg import svd, matrix_rank, pinv, inv\n",
    "from scipy.linalg import eigh, eig\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import nn\n",
    "\n",
    "import tensorly as tl\n",
    "tl.set_backend('pytorch')\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.tucker_tensor import tucker_to_tensor\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LfhKpuX7htE"
   },
   "source": [
    "## 1 Создайте 3х мерный тензор\n",
    "Размер тензора не меньше 100 по каждой из размерностей.\n",
    "\n",
    "Заполните случайными целыми числами в диапазоне от 0 до 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ap1Ozn7P8-Yj"
   },
   "source": [
    "Примечание: разложение будет корректно работать со случайным тензором, только если изначально создавать случайные ядро и матрицы, а потом по ним формировать тензор. Работайте с типом *torch.Tensor.double*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "5SzHzteOROQQ"
   },
   "outputs": [],
   "source": [
    "# Создадим тензор: размер тензора и r задаётся\n",
    "def get_tensor(size=(100,200,150), r=(10,10,10)):\n",
    "    # data - тензор с заданной размерностью\n",
    "    # U - список матриц\n",
    "    # G - ядро разложения\n",
    "    \n",
    "    assert np.all(np.array(size)>=100), 'Размер тензора не меньше 100 по каждой из размерностей.'\n",
    "    \n",
    "    G = torch.randint(10, (r[0], r[1], r[2]), requires_grad=True, dtype=torch.double)\n",
    "    U = [torch.randint(10, (size[0], r[0]), requires_grad=True, dtype=torch.double), \n",
    "         torch.randint(10, (size[1], r[1]), requires_grad=True, dtype=torch.double), \n",
    "         torch.randint(10, (size[2], r[2]), requires_grad=True, dtype=torch.double)]\n",
    "    \n",
    "    data = G\n",
    "    \n",
    "    #print(U[0].shape, data.shape)\n",
    "    data = torch.tensordot(U[0], data, dims=([1], [0]))\n",
    "    \n",
    "    #print(U[1].shape, data.shape)\n",
    "    data = torch.tensordot(U[1], data.permute([1, 0, 2]), dims=([1], [0]))\n",
    "    data = data.permute([1, 0, 2])\n",
    "    \n",
    "    #print(U[2].shape, data.shape)\n",
    "    data = torch.tensordot(U[2], data.permute([2, 1, 0]), dims=([1], [0]))\n",
    "    data = data.permute([2, 1, 0])\n",
    "    \n",
    "    return data, U, G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFuFlp2n78Tz"
   },
   "source": [
    "Сгенерируйте тензор и добавьте к нему случайный шум с размерностью *1e-2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FnUbbsYSdrsw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 200, 150]),\n",
       " [torch.Size([100, 10]), torch.Size([200, 20]), torch.Size([150, 30])],\n",
       " torch.Size([10, 20, 30]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, U, G = get_tensor(r = (10, 20, 30))\n",
    "data.shape, [u.shape for u in U], G.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "N70Xy_6u9RFa"
   },
   "outputs": [],
   "source": [
    "noise = torch.randint(10, (data.shape))*1e-2\n",
    "data += noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kp75_Ad29RL5"
   },
   "source": [
    "Вопрос:\n",
    "Почему задание не имеет смысла для полностью случайного тензора и зачем добавлять шум? *не отвечать нельзя*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VLMaT5wyE11"
   },
   "source": [
    "Ответ: Если тензор полностью случайный, то основная цель факторизации - выявление закономерностей и зависимостей - теряется, что затрудняет работу градиентного спуска. Кроме того, шум помогает градиентному спуску справляться с проблемой локальных минимумов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzninpMYD_hd"
   },
   "source": [
    "## 2 Реализуйте метод для восстановления тензора по разложению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "YDTx9ZbYD-_S"
   },
   "outputs": [],
   "source": [
    "# Функция, восстанавливающая тензор по ядру и матрицам\n",
    "def repair_tensor(G_, U):\n",
    "    # data - восстановленный тензор из матриц и ядра\n",
    "    # U - список матриц\n",
    "    # G_ - ядро разложения\n",
    "    \n",
    "    data = G_\n",
    "    \n",
    "    for i in range(len(U)):\n",
    "        numbers = list(range(G_.dim()))\n",
    "        numbers[0], numbers[i] = numbers[i], numbers[0]\n",
    "        data = torch.tensordot(U[i], data.permute(numbers), dims=([1], [0]))\n",
    "        data = data.permute(numbers)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "KvEKNuTvIIfp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1: torch.Size([150, 200, 250])\n",
      "data1_p: torch.Size([150, 200, 250])\n",
      "\n",
      " 0.0\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "r1 = (15, 30, 45)\n",
    "_, U1, G1 = get_tensor(size=(150, 200, 250), r=r1)\n",
    "\n",
    "data1 = repair_tensor(G1, U1)\n",
    "print('data1:', data1.shape)\n",
    "\n",
    "data1_p = tucker_to_tensor((G1, U1))\n",
    "print('data1_p:', data1_p.shape)\n",
    "\n",
    "print('\\n', mean_squared_error(data1.detach().numpy().flatten(), data1_p.detach().numpy().flatten()))\n",
    "print((data1==data1_p).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKqzxtaE-F16"
   },
   "source": [
    "## 3 Сделайте разложение библиотечным методом\n",
    "Пакет можете брать любой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Hlp4Jh3--fKh"
   },
   "outputs": [],
   "source": [
    "G2, U2 = tucker(data1, r1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMw1x8w8-lsh"
   },
   "source": [
    "Не забудьте померить ошибку разложения по метрике MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "HWkdb7Ip-mL3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9151234218783665e-16"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_data1 = tucker_to_tensor((G2, U2))\n",
    "mean_squared_error(data1.detach().numpy().flatten(), re_data1.detach().numpy().flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibOgeEgfD1wm"
   },
   "source": [
    "## 4 Реализуйте разложение градиентным методом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GstBYmiBF7A6"
   },
   "source": [
    "### 4.1 Реализуйте *optimizer*\n",
    "Можно взять из исходников *PyTorch* и отнаследоваться от *torch.optim.optimizer*.\n",
    "Используйте квадратичный *Loss*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Mxrtt60hF6xb"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "class Opt(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3):\n",
    "\n",
    "        defaults = dict(\n",
    "            lr=lr\n",
    "        )\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    \n",
    "    def step(self, epoch, closure=None):\n",
    "        \"\"\"Perform a single optimization step.\n",
    "\n",
    "        Args:\n",
    "            closure (Callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        \n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "        for group in self.param_groups:\n",
    "            lr = group['lr']\n",
    "            \n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                \n",
    "                if not hasattr(p, 'state'):\n",
    "                    p.state = {'m': torch.zeros_like(p), 'v': torch.zeros_like(p), 't': 0}\n",
    "                \n",
    "                state = p.state\n",
    "                state['t'] += 1\n",
    "\n",
    "                m = state['m']\n",
    "                v = state['v']\n",
    "\n",
    "                m = 0.9*m + p.grad.data/10\n",
    "                v = 0.99*v + torch.square(p.grad.data)/100\n",
    "\n",
    "                m_hat = m / (1 - 0.9 ** state['t'])\n",
    "                v_hat = v / (1 - 0.99 ** state['t'])\n",
    "\n",
    "                p.data = p.data - lr * m_hat / (torch.sqrt(v_hat) + 1e-8)\n",
    "                \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GSolH5dEJba"
   },
   "source": [
    "### 4.2 Реализуйте цикл оптимизации параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6UWpuERFTn8"
   },
   "source": [
    "Стоит параметры оптимизировать сразу на GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "CgPaeQ7XEJnD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9877241.5033, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "CPU times: total: 3min 12s\n",
      "Wall time: 34.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "r = (5, 10, 5)\n",
    "size = (100, 150, 110)\n",
    "\n",
    "data_train, _u, _g = get_tensor(size=size, r=r)\n",
    "noise = torch.randint(10, (data_train.shape))*1e-2\n",
    "data_train += noise\n",
    "data_train = data_train.detach()\n",
    "\n",
    "G = torch.randint(10, (r[0], r[1], r[2]), requires_grad=True, dtype=torch.double)\n",
    "U = [torch.randint(10, (size[0], r[0]), requires_grad=True, dtype=torch.double), \n",
    "     torch.randint(10, (size[1], r[1]), requires_grad=True, dtype=torch.double), \n",
    "     torch.randint(10, (size[2], r[2]), requires_grad=True, dtype=torch.double)]\n",
    "\n",
    "model = [nn.Parameter(U[0]), nn.Parameter(U[1]), nn.Parameter(U[2]), nn.Parameter(G)]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_train = data_train.to(device)\n",
    "for param in model:\n",
    "    param.to(device)\n",
    "\n",
    "lr = 1e-2\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Opt(model, lr=lr)\n",
    "\n",
    "\n",
    "# print(f\"PARAM 0 before: {model[0]}\")\n",
    "# print(f\"PARAM 1 before: {model[1]}\")\n",
    "# print(f\"PARAM 2 before: {model[2]}\")\n",
    "# print(f\"PARAM 3 before: {model[3]}\\n\")\n",
    "\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    data_predicted = repair_tensor(model[3], [model[0], model[1], model[2]])\n",
    "    loss = criterion(data_predicted, data_train)  \n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step(epoch)  \n",
    "\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Za8JKgR-Falk"
   },
   "source": [
    "## 5 Приведите сравнение скорости работы и ошибки восстановления методом из пакета и реализованного градиентного\n",
    "Сравнение может считаться ± объективным с размером выборки от 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "mOGKW9RHFa5D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9921703.266557436\n"
     ]
    }
   ],
   "source": [
    "predicted_data_grad = repair_tensor(model[3], [model[0], model[1], model[2]])\n",
    "\n",
    "mse_grad = mean_squared_error(data_train.detach().numpy().flatten(), predicted_data_grad.detach().numpy().flatten())\n",
    "\n",
    "print(mse_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse_package = 0.0028503482531408\n",
      "CPU times: total: 12.2 s\n",
      "Wall time: 2.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mses = np.array([])\n",
    "\n",
    "for i in range(10):\n",
    "    data, U, G = get_tensor()\n",
    "    noise = torch.randint(10, (data.shape))*1e-2\n",
    "    data += noise\n",
    "    \n",
    "    re_data = tucker_to_tensor((G, U))\n",
    "    mses = np.append(mses, mean_squared_error(data.detach().numpy().flatten(), re_data.detach().numpy().flatten()))\n",
    "\n",
    "print('mse_package =', np.mean(mses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
